{
  "cells": [
    {
      "metadata": {
        "_uuid": "86130c19d87761a42522aa8774b6b62707e117b3"
      },
      "cell_type": "markdown",
      "source": "**MNIST Data Recognition**"
    },
    {
      "metadata": {
        "_uuid": "6ea036004b3726895456650beb19334bcad2c319"
      },
      "cell_type": "markdown",
      "source": "Firstly, import the necessary libraries"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC\nprint(\"Libraries Imported\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "Then import the data:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f946a7e4427e64f18f30cb1e2b4ab604cda34598"
      },
      "cell_type": "code",
      "source": "train_data = pd.read_csv(\"../input/train.csv\")\ntest_data = pd.read_csv(\"../input/test.csv\")\nprint(\"Data imported\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2fc9d1b05388abe949e73e5755718b048ebd9186"
      },
      "cell_type": "markdown",
      "source": "We can take a look at the data:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d9768f8f0820a3472cf53b6730ee47833aee6c17"
      },
      "cell_type": "code",
      "source": "print(\"Number of images: %d\" % len(train_data))\ntrain_data.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1849db6a8da0794531f0cf98b6e7487665a000f0"
      },
      "cell_type": "markdown",
      "source": "We can see that there are 42k images and each is assigned a label, which is the digit the image corresponds to, and 784 columns that represent a flattened array of pixel values.\n\nTo take a look at one of the images, take that images row of pixels as a pandas \"Series\" dataframe. Then convert it into a numpy array and reshape it into a 28x28 array (image)."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3056a7d6d3be6fb2cc934c7ed3b9749cd3a00864"
      },
      "cell_type": "code",
      "source": "image1 = train_data.loc[0, train_data.columns != \"label\"]\nplt.imshow(np.array(image1).reshape((28, 28)), cmap=\"gray\")\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a4706e3906e162c49e749456b2dad32f6f74c4b3"
      },
      "cell_type": "markdown",
      "source": "Each image is 28x28 pixels in size. This image corresponds to the digit \"1\".\n\nNow take a look at the distribution and range of values that the pixels can have:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9af03bb3fc5b49ed38709e800e7821dc67e60af6"
      },
      "cell_type": "code",
      "source": "plt.hist(image1)\nplt.xlabel(\"Pixel Intensity\")\nplt.ylabel(\"Counts\")\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e11f64d851994c411f7cd1f189e0ece4c5e9688c"
      },
      "cell_type": "markdown",
      "source": "Each pixel in the pixel array has an integer value between 0 and 255 which corresponds to its grayscale value. Most of the image is composed of pixels with values close to zero, which makes sense as the image above shows most of the image, apart from where the digit is drawn, is dark.\n\nTo make the training data less complex, it is often commonplace to normalize the data. In this case, divide each value of pixel intensity by the maximum value it can have (255) so that the range of intensities decreases from 0->255 to 0->1 instead.\n\nAlso, to determine the models accuracy and to check for overfitting/underfitting, we want to split the training data into a training dataset and test dataset.\n\nFirstly, split the training data into images and labels and divide each pixel intensity by 255.\n\nThen, split the training data into a 3:1 ratio of training data and test data so that the model has some unseen data to perform accuracy tests on. Use random_state = 1 to set the RNG seed so that the resulting datasets can be duplicated.\n\nFinally, flatten the label data into a 1d array."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "926c4c1cc08cbc80b58b9ce4e77fa588deff26b3"
      },
      "cell_type": "code",
      "source": "#clean and split data\ntrain_images = train_data.loc[:, train_data.columns != \"label\"] / 255\ntrain_labels = train_data.label\ntest_data = test_data.loc[:, :] / 255\nx_train, x_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.25, random_state=1)\ny_train = y_train.values.ravel()\ny_test = y_test.values.ravel()\n\nprint(\"Data cleaned and split\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e57a12cfa3951d1402c666a314e16f3d5eaef771"
      },
      "cell_type": "markdown",
      "source": "This section can be ignored. It just gives the choice to run tests on smaller samples of the data."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e1c9b72e916fa5562ffdd92f4ed6b265211ecf3"
      },
      "cell_type": "code",
      "source": "sample_size = len(x_train)\nx_train_sample = x_train.iloc[0:sample_size, :]\ny_train_sample = y_train[0:sample_size]\nx_test_sample = x_test.iloc[0:sample_size, :]\ny_test_sample = y_test[0:sample_size]\n\nprint(\"Data samples created\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5b94e2229004d5ecb653617e899e50bb89006c8b"
      },
      "cell_type": "markdown",
      "source": "Now this is where the magic begins. We choose the SVC (Support Vector Classifier) model with default parameters to begin with and fit it with the training data."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ee94a30f0494806a2efd751e678d8a5a6e5fc369"
      },
      "cell_type": "code",
      "source": "#SVC classifier\nmodel = SVC()\nmodel.fit(x_train_sample, y_train_sample)\nprint(\"Model trained\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "213e5c3299dffb40a928b4dd88fd7b5ccfb20530"
      },
      "cell_type": "markdown",
      "source": "Now calculate the accuracy of the model when tested with training data and test data. If the model performs well on the training dataset and poorly on the test dataset, then we know that the model may likely be overfitting. However, if the model performs poorly on both datasets, we might suspect that the model has instead underfitted the data.\n\nThus, for a well fitted model, we expect the training and test accuracies to be pretty close together. If the accuracy scores are low, then a number of extra measures might need to be taken, such as cleaning/manipulating the dataset more, increasing/decreasing the number of images used or tuning the model parameters."
    },
    {
      "metadata": {
        "_uuid": "b28aae7ca174833a9c32eda8ad612d00436e62fc",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#training metrics\ntrain_predicts = model.predict(x_train_sample)\ntrain_acc = round(accuracy_score(y_train_sample, train_predicts) * 100)\nprint(\"Training Accuracy: %d%%\" %train_acc)\n\n#test metrics\ntest_predicts = model.predict(x_test_sample)\ntest_acc = round(accuracy_score(y_test_sample, test_predicts) * 100)\nprint(\"Training Accuracy: %d%%\" %test_acc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bc3d763a6b5431c5cf24f0e70e0c403586f56c38"
      },
      "cell_type": "markdown",
      "source": "In this case, on the first run, the model achieved a 94% training accuracy and 94% test accuracy. This means that the model probably isn't overfitting or underfitting, which is good news. To increase this accuracy, the models parameters might need to be tuned.\n\nFinally, use the test submission data to create predictions and output them to a csv file for submission to Kaggle."
    },
    {
      "metadata": {
        "_uuid": "fa278d5f449eded2e9a3f6689b37e21269ea9e04",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#submission predictions\npredictions = model.predict(test_data)\nprint(\"Finished submission predictions\")\n\n#export submission data\nsubmission = pd.DataFrame(predictions)\nsubmission.index.name = \"ImageId\"\nsubmission.index += 1\nsubmission.columns = [\"Label\"]\nsubmission.to_csv(\"digit_submissions.csv\", header=True)\n\nprint(\"Exported submission predictions\")",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}